{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc1e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db377a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\himanshi rawat\\anaconda3\\lib\\site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\himanshi rawat\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5dc817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bdd29c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-telehealt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telemedici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-people-di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL\n",
       "0         1  https://insights.blackcoffer.com/is-telehealth...\n",
       "1         2  https://insights.blackcoffer.com/how-telehealt...\n",
       "2         3  https://insights.blackcoffer.com/is-telemedici...\n",
       "3         4  https://insights.blackcoffer.com/is-telehealth...\n",
       "4         5  https://insights.blackcoffer.com/how-people-di...\n",
       "..      ...                                                ...\n",
       "145     146  https://insights.blackcoffer.com/blockchain-fo...\n",
       "146     147  https://insights.blackcoffer.com/the-future-of...\n",
       "147     148  https://insights.blackcoffer.com/big-data-anal...\n",
       "148     149  https://insights.blackcoffer.com/business-anal...\n",
       "149     150  https://insights.blackcoffer.com/challenges-an...\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c89916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-telehealt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telemedici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-people-di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0       1  https://insights.blackcoffer.com/is-telehealth...\n",
       "1       2  https://insights.blackcoffer.com/how-telehealt...\n",
       "2       3  https://insights.blackcoffer.com/is-telemedici...\n",
       "3       4  https://insights.blackcoffer.com/is-telehealth...\n",
       "4       5  https://insights.blackcoffer.com/how-people-di..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d3b46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44cec3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://insights.blackcoffer.com/which-one-is-better-ai-or-big-data/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[30,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a34d590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = df.iloc[30,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591120a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4180c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = requests.get(link, headers=headers).text\n",
    "data = BeautifulSoup(source, 'lxml')\n",
    "article = data.find('article')\n",
    "title = article.h1.text\n",
    "body =  article.find('div', class_='td-post-content').text\n",
    "date = article.find('div', class_='td-module-meta-info').time.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d82fee8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is big data the same as AI?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b965f238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAbstract\\nAI and Big Data are mutually integrated components. The size of data collected around the world is expanding at an exponential rate, as well. The data is becoming more meaningful and contextually relevant, breaking new ground for machine learning and artificial intelligence (AI), and even moving these technologies from the lab to production. That is, the challenge has switched from gathering huge volumes of data to comprehending it, i.e., transforming data into knowledge, conclusions, and actions. This special issue aims to bring attention to the algorithmic difficulties and opportunities, as well as the social and ethical implications of Big Data. This article examines the relationship between AI and Big Data, as well as their comparison and mutual reliance.\\nIs Big Data even a fair comparison to AI?\\nThe two technologies do have one thing in common: they are both fascinating. A New Vantage their firms invest, construct, or start up Big Data and AI initiatives.\\nMore partner poll on Big Data and AI by c-level c-managers has discovered that 97.2% of managers say that importantly, 76.5 percent of CEOs believe AI and Big Data are becoming increasingly knotted, and that increased data availability is empowering AI and cognitive projects within their companies. It is a natural error, partially because the two go together, to pit artificial intelligence against big data. They are, however, distinct tools for accomplishing the same goal. But first and foremost, the two must be defined. Many folks are completely unaware of the situation.\\nThe differences between AI and Big Data\\n“There are many people who don’t know much about the true big data or big data analysis,” says Alan Morrison, a senior research fellow with PriceWaterhouse Coopers, a consultancy giant. “AI’s beyond a few prominent cases.\\nHe says that Big Data is the raw input to be cleaned, structured, and integrated to be usable, and artificial intelligence is the output of the processed data. That is what distinguishes them both.\\nArtificial intelligence is a computer form that makes it possible for machines to execute cognitive tasks such as behaving or reacting to stimuli in the same manner as humans. Traditional computer applications react to data, but the reactions and answers must be hand-coded. If a curveball of any sort is thrown, the program cannot react, like an unexpected result. AI systems therefore constantly adapt their behavior to accommodate and change the results.\\nAn AI-enabled device is designed for analysis and interpretation of data and subsequently for the solution of the problem and/or for the solution of the problem. The computer once learns to act or to react to a given result and in the future understands how to act in the same way with machine learning.\\nOld computing is big data. It doesn’t act, it only looks for results. It defines incredibly vast data sets but also much-diversified data. Structured data, such as transactional data in a relational database, and less structured or unstructured data like photographs, e-mail data, sensor data, etc. may be included in big data sets.\\nThey also have use distinctions. The main purpose of big data is to get insight. How does Netflix know which films or TV episodes you propose based on what you see? Because it examines and deduces the behaviors and preferences of other consumers, you may experience the same.\\xa0\\nAI has to do with making decisions, and with learning to decide better. Whether it’s software for self-adjustment, self-driving cars, or medical examination, AI does human activities, but faster and with fewer errors.\\nBig Data and Artificial Intelligence Working Together\\nWhile highly distinct, AI and Big Data nonetheless work together successfully. This is because AI, particularly machine learning, needs data to construct its intelligence. For example, a machine learner IMR app looks at thousands of aircraft photographs so it can recognize what an aircraft is in the future.\\nThe key stage in data preparation, which Morrison noted, naturally exists. “The initial input is Big Data, but the model needs to be structured and integrated sufficiently to enable machines to reliably detect useful patterns in the data,” he said.\\nBig data involves vast volumes of data, and before anything can be done, the wheat must be sifted. Data already “cleared” in AI and ML and deleted external duplicate and superfluous data. That’s the first big step.\\nAI can thrive afterward. The data required to train the learning algorithms can be provided by large data. The initial training, a sort of pump-priming, and data received regularly are two sorts of data learning. After the first training is complete, AI programs never stop learning. You continue to generate fresh data and adapt your actions as the data changes. Initially and continuously, data are therefore necessary.\\nBoth computer methods do, although differently, use pattern recognition. Big data analytics detect patterns through sequence analysis, sometimes cold data or not newly collected data. Hadoop, the underlying architecture of Big Data analytics, is a batch method built for low server use at night.\\nMachine learning learns from the data gathered and continues to gather. Your car never stops collecting data and continues to learn and refine its procedures. The data is always fresh and has always been acted upon.\\nBig Data’s Role in AI\\nAI was forever discussed. It was the drawing-point of the 1999 blockbuster “The Matrix.” The people fought machines that were too clever. However, until recently, AI has remained a technology periphery.\\nThe huge breakthrough was the emergence of massively parallel processing systems. The existing AI algorithms have thus been considerably accelerated and made feasible.\\nBig data for feeding processors enables machine study algorithms to learn how to recreate certain activities, including data collection to speed up the machine. No findings like people do are inferred by AI. The process is tested and mistaken and requires enormous data to teach the AI.\\nThe more information an AI app has, the better the result it can achieve. Because of slow processors and tiny data sets, AI had not worked successfully in the past. No sensors like today could be used to build a car with dozens of sensors. And, because the Internet is not widely available, there were no real-time data.\\nWe have all that we need now, quick processors, input devices, the network, and huge volumes of data sets. It’s safe to assume that without big data, there’s no artificial intelligence.\\nAI’s Role in Big Data\\nBig data is handled using AI ideally and efficiently. Big data is already in our world. The web-based and offline data cover a large number of topics, including individuals, routine, preferences, etc., and non-living things, property, and uses.\\nBig data, as the sentence implies, are just large, large or large, or complex, or a large quantity of certain information that you can understand and store on a computer or machine. Big data is a professional area where various forms of extracting, analyzing, or dealing with datasets are studied which are so complicated that typical data processing tools can handle them. A system for extending the extraction and analysis capacity of such a volume of data is required.\\nThis large inventory of data, if appropriately used, can provide the sector/industry where the data set belongs with significant insights and business analysis. As a result, artificially intelligent algorithms are being developed for humans to benefit from vast amounts of complex data. The AI and Big Data combination make predictive modeling possible in the natural resources sector. For fast and easy examination of huge graphic data, geospatial data, time data, seismic interpretation, and characterization of the reservoir AI is used in Big Data.\\nHow companies use AI and Big Data\\nThis part of our study examines how the synergy between the AI algorithm and Big Data analysis is used to benefit applications, such as:\\n● Natural language processing records and connects millions of human-language samples with their matching language computer programming translations. Computers are so designed and deployed to help companies evaluate and handle enormous quantities of human language data.\\n\\xa0●In the educational field, AI synchronizes Big Data Analytics to several purposes, for instance, tracking and analyzing when a student enters the system, how much time they spend on the various pages of the system, and students’ overall progress with time. It is also helpful to measure teacher efficiency. The performance of teachers is analyzed and quantified in terms of the number of students, various courses, aspirations of students, demographics of students, patterns of behavior, and much other information.\\n● Collection, analysis, and usage of consumer insights can be employed with the AI capacities. Companies in this area can analyze their client data together with customer behavior data simultaneously to develop thorough client profiles to be utilized for content creation for a wide range of target audiences, content recommendation, and content performance measurement.\\n●The worldwide government uses AI for many applications including public facial recognition, traffic management vehicle recognition, population populations, financial classifications, energy exploration, environmental conservation, infrastructure management, criminal investigations, etc.\\n●The big pool of health data benefited health care professionals. AI has eased medical prescriptions and health analyses. Hospitals employ data gathered from millions of mobile and sensor devices that enable doctors to use medicine based on evidence. Chronic diseases are also recognized and tracked more quickly.\\nInsurance, retail and bulk trade, transport, and energies & services are also domains in which AI is employed in Big Data.\\nFinal Thoughts on AI and Big Data\\nFinally, we can establish that there are significant expenditures in the use of AI in Big Data analysis for the benefit of everyone. Data sets will continue to grow, and as a result, the level of application and investment will grow as well. Human intervention will remain relevant, as it always has been, albeit its importance is expected to diminish with time.\\n“Artificial Intelligence is useless without data, and data is insurmountable without AI,” one could argue. Furthermore, both AI and Big Data would be impossible to achieve without human engagement and interaction.\\nMachine learning solutions enabled by AI systems are the future of company technology and processes development. Machine Learning programs with this capability automate data analysis and uncover new insights that were previously unimaginable when data was processed manually or using traditional approaches. This ability to increase the predictability of certain events allows us to radically rethink how we approach everything.\\nBlackcoffer Insights 31: Adrita Anan, Holy Cross College- Dhaka,\\xa0Bangladesh.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a70100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Abstract AI and Big Data are mutually integrated components. The size of data collected around the world is expanding at an exponential rate, as well. The data is becoming more meaningful and contextually relevant, breaking new ground for machine learning and artificial intelligence (AI), and even moving these technologies from the lab to production. That is, the challenge has switched from gathering huge volumes of data to comprehending it, i.e., transforming data into knowledge, conclusions, and actions. This special issue aims to bring attention to the algorithmic difficulties and opportunities, as well as the social and ethical implications of Big Data. This article examines the relationship between AI and Big Data, as well as their comparison and mutual reliance. Is Big Data even a fair comparison to AI? The two technologies do have one thing in common: they are both fascinating. A New Vantage their firms invest, construct, or start up Big Data and AI initiatives. More partner poll on Big Data and AI by c-level c-managers has discovered that 97.2% of managers say that importantly, 76.5 percent of CEOs believe AI and Big Data are becoming increasingly knotted, and that increased data availability is empowering AI and cognitive projects within their companies. It is a natural error, partially because the two go together, to pit artificial intelligence against big data. They are, however, distinct tools for accomplishing the same goal. But first and foremost, the two must be defined. Many folks are completely unaware of the situation. The differences between AI and Big Data “There are many people who don’t know much about the true big data or big data analysis,” says Alan Morrison, a senior research fellow with PriceWaterhouse Coopers, a consultancy giant. “AI’s beyond a few prominent cases. He says that Big Data is the raw input to be cleaned, structured, and integrated to be usable, and artificial intelligence is the output of the processed data. That is what distinguishes them both. Artificial intelligence is a computer form that makes it possible for machines to execute cognitive tasks such as behaving or reacting to stimuli in the same manner as humans. Traditional computer applications react to data, but the reactions and answers must be hand-coded. If a curveball of any sort is thrown, the program cannot react, like an unexpected result. AI systems therefore constantly adapt their behavior to accommodate and change the results. An AI-enabled device is designed for analysis and interpretation of data and subsequently for the solution of the problem and/or for the solution of the problem. The computer once learns to act or to react to a given result and in the future understands how to act in the same way with machine learning. Old computing is big data. It doesn’t act, it only looks for results. It defines incredibly vast data sets but also much-diversified data. Structured data, such as transactional data in a relational database, and less structured or unstructured data like photographs, e-mail data, sensor data, etc. may be included in big data sets. They also have use distinctions. The main purpose of big data is to get insight. How does Netflix know which films or TV episodes you propose based on what you see? Because it examines and deduces the behaviors and preferences of other consumers, you may experience the same.  AI has to do with making decisions, and with learning to decide better. Whether it’s software for self-adjustment, self-driving cars, or medical examination, AI does human activities, but faster and with fewer errors. Big Data and Artificial Intelligence Working Together While highly distinct, AI and Big Data nonetheless work together successfully. This is because AI, particularly machine learning, needs data to construct its intelligence. For example, a machine learner IMR app looks at thousands of aircraft photographs so it can recognize what an aircraft is in the future. The key stage in data preparation, which Morrison noted, naturally exists. “The initial input is Big Data, but the model needs to be structured and integrated sufficiently to enable machines to reliably detect useful patterns in the data,” he said. Big data involves vast volumes of data, and before anything can be done, the wheat must be sifted. Data already “cleared” in AI and ML and deleted external duplicate and superfluous data. That’s the first big step. AI can thrive afterward. The data required to train the learning algorithms can be provided by large data. The initial training, a sort of pump-priming, and data received regularly are two sorts of data learning. After the first training is complete, AI programs never stop learning. You continue to generate fresh data and adapt your actions as the data changes. Initially and continuously, data are therefore necessary. Both computer methods do, although differently, use pattern recognition. Big data analytics detect patterns through sequence analysis, sometimes cold data or not newly collected data. Hadoop, the underlying architecture of Big Data analytics, is a batch method built for low server use at night. Machine learning learns from the data gathered and continues to gather. Your car never stops collecting data and continues to learn and refine its procedures. The data is always fresh and has always been acted upon. Big Data’s Role in AI AI was forever discussed. It was the drawing-point of the 1999 blockbuster “The Matrix.” The people fought machines that were too clever. However, until recently, AI has remained a technology periphery. The huge breakthrough was the emergence of massively parallel processing systems. The existing AI algorithms have thus been considerably accelerated and made feasible. Big data for feeding processors enables machine study algorithms to learn how to recreate certain activities, including data collection to speed up the machine. No findings like people do are inferred by AI. The process is tested and mistaken and requires enormous data to teach the AI. The more information an AI app has, the better the result it can achieve. Because of slow processors and tiny data sets, AI had not worked successfully in the past. No sensors like today could be used to build a car with dozens of sensors. And, because the Internet is not widely available, there were no real-time data. We have all that we need now, quick processors, input devices, the network, and huge volumes of data sets. It’s safe to assume that without big data, there’s no artificial intelligence. AI’s Role in Big Data Big data is handled using AI ideally and efficiently. Big data is already in our world. The web-based and offline data cover a large number of topics, including individuals, routine, preferences, etc., and non-living things, property, and uses. Big data, as the sentence implies, are just large, large or large, or complex, or a large quantity of certain information that you can understand and store on a computer or machine. Big data is a professional area where various forms of extracting, analyzing, or dealing with datasets are studied which are so complicated that typical data processing tools can handle them. A system for extending the extraction and analysis capacity of such a volume of data is required. This large inventory of data, if appropriately used, can provide the sector/industry where the data set belongs with significant insights and business analysis. As a result, artificially intelligent algorithms are being developed for humans to benefit from vast amounts of complex data. The AI and Big Data combination make predictive modeling possible in the natural resources sector. For fast and easy examination of huge graphic data, geospatial data, time data, seismic interpretation, and characterization of the reservoir AI is used in Big Data. How companies use AI and Big Data This part of our study examines how the synergy between the AI algorithm and Big Data analysis is used to benefit applications, such as: ● Natural language processing records and connects millions of human-language samples with their matching language computer programming translations. Computers are so designed and deployed to help companies evaluate and handle enormous quantities of human language data.  ●In the educational field, AI synchronizes Big Data Analytics to several purposes, for instance, tracking and analyzing when a student enters the system, how much time they spend on the various pages of the system, and students’ overall progress with time. It is also helpful to measure teacher efficiency. The performance of teachers is analyzed and quantified in terms of the number of students, various courses, aspirations of students, demographics of students, patterns of behavior, and much other information. ● Collection, analysis, and usage of consumer insights can be employed with the AI capacities. Companies in this area can analyze their client data together with customer behavior data simultaneously to develop thorough client profiles to be utilized for content creation for a wide range of target audiences, content recommendation, and content performance measurement. ●The worldwide government uses AI for many applications including public facial recognition, traffic management vehicle recognition, population populations, financial classifications, energy exploration, environmental conservation, infrastructure management, criminal investigations, etc. ●The big pool of health data benefited health care professionals. AI has eased medical prescriptions and health analyses. Hospitals employ data gathered from millions of mobile and sensor devices that enable doctors to use medicine based on evidence. Chronic diseases are also recognized and tracked more quickly. Insurance, retail and bulk trade, transport, and energies & services are also domains in which AI is employed in Big Data. Final Thoughts on AI and Big Data Finally, we can establish that there are significant expenditures in the use of AI in Big Data analysis for the benefit of everyone. Data sets will continue to grow, and as a result, the level of application and investment will grow as well. Human intervention will remain relevant, as it always has been, albeit its importance is expected to diminish with time. “Artificial Intelligence is useless without data, and data is insurmountable without AI,” one could argue. Furthermore, both AI and Big Data would be impossible to achieve without human engagement and interaction. Machine learning solutions enabled by AI systems are the future of company technology and processes development. Machine Learning programs with this capability automate data analysis and uncover new insights that were previously unimaginable when data was processed manually or using traditional approaches. This ability to increase the predictability of certain events allows us to radically rethink how we approach everything. Blackcoffer Insights 31: Adrita Anan, Holy Cross College- Dhaka, Bangladesh. '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_body = body.replace('\\n',' ')\n",
    "new_body = new_body.replace('\\xa0',' ')\n",
    "\n",
    "new_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "416f3c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Now we can do exactly the same steps, but applied to each one of the URLs by iterating the instances \\nwith a for loop, also we will create a csv file in which we will write \\neverything we gather following the same order as they appeared in the origin file:'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Now we can do exactly the same steps, but applied to each one of the URLs by iterating the instances \n",
    "with a for loop, also we will create a csv file in which we will write \n",
    "everything we gather following the same order as they appeared in the origin file:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74565a9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'h1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m BeautifulSoup(source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m art \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[43mart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh1\u001b[49m\u001b[38;5;241m.\u001b[39mtext \n\u001b[0;32m     14\u001b[0m titles\u001b[38;5;241m.\u001b[39mappend(title)\n\u001b[0;32m     15\u001b[0m body \u001b[38;5;241m=\u001b[39m art\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m,class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd-post-content\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'h1'"
     ]
    }
   ],
   "source": [
    "titles=[]\n",
    "bodies=[]\n",
    "\n",
    "csv_file = open('blackcoffer_WS.csv', 'w', encoding='UTF8')\n",
    "\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Id', 'Title', 'Text'])\n",
    "\n",
    "for index in range(0, df.shape[0], 1):\n",
    "  source = requests.get(df.iloc[index,1],headers=headers).text\n",
    "  data = BeautifulSoup(source, 'lxml')\n",
    "  art = data.find('article')\n",
    "  title = art.h1.text \n",
    "  titles.append(title)\n",
    "  body = art.find('div',class_='td-post-content').text\n",
    "  body = body.replace('\\n',' ')\n",
    "  body = body.replace('\\xa0',' ')\n",
    "  try:\n",
    "         footer = art.find('div',class_='td-post-content').pre.text\n",
    "         body = body.replace(footer,'')\n",
    "  except Exception as x:\n",
    "    footer=''\n",
    "  bodies.append(body)\n",
    "  csv_writer.writerow([df.iloc[index,0], title, body])\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585bc1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WS_file = pd.read_csv('./blackcoffer_WS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a71650",
   "metadata": {},
   "outputs": [],
   "source": [
    "WS_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6949a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54528072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
